# flutter_vision

### To start the App, after installing Flutter, open the project with Visual Studio Code, then start an emulator (iOS or Android) or connect your physical device to your computer. Then in Visual Studio Code press fn + control + F5 

### All the code is in the /lib folder

### Put your Google Vision API key in /lib/components/take_picture.dart  "https://vision.googleapis.com/v1/images:annotate?key=YOUR_API_KEY";

### to configure AWS https://aws.amazon.com/blogs/machine-learning/build-your-own-face-recognition-service-using-amazon-rekognition/

# Some pictures of the project

## Select an image
![Alt text](/pic/1.jpg?raw=true "Select a picture")

## From the camera or from the gallery
![Alt text](/pic/2.jpg?raw=true "Select a picture")

## Display the image and send an API request
![Alt text](/pic/3.jpg?raw=true "Select a picture")

## Display the result from Google Vision API
![Alt text](/pic/4.jpg?raw=true "Select a picture")

## Adding a picture to AWS bucket with the name of the person
![Alt text](/pic/5.jpg?raw=true "Add to bucket")

## Display the result from our own AWS model based on the previously uploaded pictures
![Alt text](/pic/6.jpg?raw=true "Identify the person")
